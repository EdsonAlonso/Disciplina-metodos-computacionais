{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to quantify the computational cost of a matrix computation is to count the total number of *floating-point operations* or *flops*. A flop is an addition, subtraction, multiplication, or division of two [floating-point numbers](https://en.wikipedia.org/wiki/Floating-point_arithmetic#Floating-point_numbers).\n",
    "\n",
    "We can easily define the total number of flops associated with simple matrix operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Product of a scalar $\\alpha$ and an $N \\times 1$ vector $\\mathbf{x}$**\n",
    "\n",
    "$$\n",
    "\\alpha \\, \\begin{bmatrix} x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_{N} \\end{bmatrix} = \n",
    "\\begin{bmatrix} \\alpha \\, x_{1} \\\\ \\alpha \\, x_{2} \\\\ \\vdots \\\\ \\alpha \\, x_{N} \\end{bmatrix} \\: .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be easily verified that this operation requires $N$ multiplications and, consequently, its computational cost is $N$ flops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Dot product of two $N \\times 1$ vectors $\\mathbf{x}$ and $\\mathbf{y}$**\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^{\\top}\\mathbf{y} = x_{1} \\, y_{1} + x_{2} \\, y_{2} + \\cdots + x_{N} \\, y_{N} \\: .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are $N$ multiplications and $N - 1$ additions. Consequently, the dot product of vectors requires $2N - 1 \\approx 2N$ flops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Hadamard (or eletrywise) product of two $N \\times 1$ vectors $\\mathbf{x}$ and $\\mathbf{y}$**\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\circ \\mathbf{y} = \n",
    "\\begin{bmatrix} x_{1} \\, y_{1} \\\\ x_{2} \\, y_{2} \\\\ \\vdots \\\\ x_{N} \\, y_{N} \\end{bmatrix} \\: .\n",
    "$$\n",
    "\n",
    "$N$ flops, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Outer product of an $N \\times 1$ vector $\\mathbf{x}$ and an $M \\times 1$ vector $\\mathbf{y}$**\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\otimes \\mathbf{y}^{\\top} = \n",
    "\\begin{bmatrix}\n",
    "x_{1} \\, \\mathbf{y}^{\\top} \\\\\n",
    "x_{2} \\, \\mathbf{y}^{\\top}\\\\\n",
    "\\vdots \\\\\n",
    "x_{N} \\, \\mathbf{y}^{\\top}\n",
    "\\end{bmatrix} \\: .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$N M$ flops, ok?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Product of an $N \\times M$ matrix $\\mathbf{A}$ and an $M \\times 1$ vector $\\mathbf{x}$**\n",
    "\n",
    "By using the dot product formulation, it can be easily shown that the total number of flops required for computing the resulting vector is $N \\left( 2M - 1 \\right) \\approx 2NM$ flops. In the notebook ([`matrix-vector.ipynb`](https://nbviewer.jupyter.org/github/birocoles/Disciplina-metodos-computacionais/blob/master/Content/matrix-vector.ipynb)), we have learned three different ways of computing the product $\\mathbf{A} \\mathbf{x}$. What is the total number of flops associated with each one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Product of an $N \\times M$ matrix $\\mathbf{A}$ and an $M \\times L$ matrix $\\mathbf{B}$**\n",
    "\n",
    "By using the examples presented above, it can be shown that the total number of flops required for computing the resulting matrix is $L \\left[ N \\left( 2M - 1 \\right) \\right] \\approx 2NML$ flops. In the notebook ([`matrix-matrix.ipynb`](https://nbviewer.jupyter.org/github/birocoles/Disciplina-metodos-computacionais/blob/master/Content/matrix-matrix.ipynb)), we have learned five different algorithms for computing the product $\\mathbf{A} \\mathbf{B}$. What is the total number of flops associated with each one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise (extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf{A}$ be an $N \\times M$ matrix, $\\mathbf{B}$ be an $M \\times L$ matrix, and $\\mathbf{C}$ be an $L \\times P$ matrix. Consider the problem of computing the following matrix:\n",
    "\n",
    "$$\n",
    "\\mathbf{E} = \\mathbf{A} \\, \\mathbf{B} \\, \\mathbf{C} \\: .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that this product can be computed by following two different approaches:\n",
    "\n",
    "$$\n",
    "\\underbrace{\\left( \\mathbf{A} \\, \\mathbf{B}\\right) \\mathbf{C}}_{\\text{approach 1}} = \n",
    "\\underbrace{\\mathbf{A} \\left( \\mathbf{B} \\, \\mathbf{C} \\right)}_{\\text{approach 2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, what is the total number of flops required to compute $\\mathbf{E}$ by following each approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
